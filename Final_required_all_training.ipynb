{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/02\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "# import xgboost as xgb\n",
    "from itertools import tee, islice\n",
    "from ROOT import TFile, TCanvas, TPad, TPaveLabel, TPaveText, TTree, TH1F, TF1\n",
    "from root_numpy import root2array, tree2array, array2tree, array2root\n",
    "import sys\n",
    "from ROOT import gROOT, AddressOf\n",
    "from root_numpy import root2array, rec2array\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = 'back.root'\n",
    "signal = 'signal.root'\n",
    "# out_dir = '/afs/cern.ch/user/s/sraj/public/plot'\n",
    "treeName_back = \"tagsDumper/trees/thq_125_13TeV_THQLeptonicTag\"\n",
    "treeName_signal = \"tagsDumper/trees/tth_125_13TeV_THQLeptonicTag\"\n",
    "columns = ['dipho_pt','dipho_phi','dipho_eta','dipho_e','dipho_mass','dipho_leadPt','dipho_leadEt','dipho_leadEta','dipho_leadPhi','dipho_subleadEta','bjet1_pt',\n",
    "          'bjet2_pt','bjet1_eta','bjet2_eta','jet1_pt','jet2_pt','jet1_eta','n_jets']\n",
    "\n",
    "columns = [c.strip() for c in columns]\n",
    "columns = (b.replace(\" \", \"_\") for b in columns)\n",
    "columns = list(b.replace(\"-\", \"_\") for b in columns)\n",
    "\n",
    "mc_arr = root2array(back, treeName_back, columns)\n",
    "data_arr = root2array(signal, treeName_signal, columns)\n",
    "\n",
    "signal = rec2array(data_arr)\n",
    "backgr = rec2array(mc_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sklearn data is usually organised\n",
    "# into one 2D array of shape (n_samples x n_features)\n",
    "# containing all the data and one array of categories\n",
    "# of length n_samples\n",
    "X = np.concatenate((signal, backgr))\n",
    "y = np.concatenate((np.ones(signal.shape[0]),\n",
    "                    np.zeros(backgr.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev,X_eval, y_dev,y_eval = train_test_split(X, y,\n",
    "                                              test_size=0.33, random_state=42)\n",
    "X_train,X_test, y_train,y_test = train_test_split(X_dev, y_dev,\n",
    "                                                  test_size=0.33, random_state=410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=2,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1, n_estimators=100, random_state=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator= tree.DecisionTreeClassifier(max_depth=2),\n",
    "                          n_estimators=100, random_state=1,learning_rate=1)\n",
    "# Fit the decision tree classifier\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create and run the SVC model with an rbf kernel\n",
    "## some tuning has been done to get the gamma and C values\n",
    "clf = SVC(C =2.0, kernel = 'rbf', tol = 0.001, gamma = 0.05)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DNN\n",
    "#define model for training\n",
    "clf = Sequential()\n",
    "clf.add(Dense(300, activation= 'relu', input_shape = (18,)))\n",
    "# clf.add(Dense(300, activation= 'relu'))\n",
    "# clf.add(Dense(300, activation= 'relu'))\n",
    "# clf.add(Dense(300,activation= 'relu'))\n",
    "# clf.add(Dense(300,activation= 'relu'))\n",
    "clf.add(Dense(1, activation= 'sigmoid'))\n",
    "\n",
    "clf.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "# clf.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, epochs = 30, batch_size= 900, validation_split = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier object and train\n",
    "# Add code here to include other claassifiers (MLP, BDT,...)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(300,), activation='relu',max_iter=2000, random_state=0)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bkg_test = X_test[y_test==0]\n",
    "X_sig_test = X_test[y_test==1]\n",
    "y_bkg_test = y_test[y_test==0]\n",
    "y_sig_test = y_test[y_test==1]\n",
    "# if hasattr(clf, \"predict_proba\"):\n",
    "#     tCut = 0.\n",
    "#     y_bkg_pred = (clf.decision_function(X_bkg_test) >= tCut).astype(bool)\n",
    "#     y_sig_pred = (clf.decision_function(X_sig_test) >= tCut).astype(bool)\n",
    "# else:\n",
    "pMin = 0.9\n",
    "y_bkg_pred = (clf.predict_proba(X_bkg_test) >= pMin).astype(bool)\n",
    "y_sig_pred = (clf.predict_proba(X_sig_test) >= pMin).astype(bool)\n",
    "#for DNN there is no need of index[:,1] in \"y_bkg_pred = (clf.predict_proba(X_bkg_test)[:,1]  >= pMin).astype(bool)\n",
    "#\" and \"y_sig_pred = (clf.predict_proba(X_sig_test)[:,1]  >= pMin).astype(bool)\n",
    "#\" as index 1 is out of bounds for axis 1 with size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = metrics.accuracy_score(y_sig_test, y_sig_pred)        # = = Prob(t >= tCut|sig)\n",
    "print('power of test with respect to signal = ', power)\n",
    "\n",
    "#  Add code here to obtain the background efficiency\n",
    "# = size of test alpha = = Prob(t >= tCut|bkg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make histogram of decision function\n",
    "plt.figure()                                     # new window\n",
    "matplotlib.rcParams.update({'font.size':14})     # set all font sizes\n",
    "tTest = clf.predict_proba(X_test)\n",
    "# if hasattr(clf, \"decision_function\"):\n",
    "#     tTest = clf.decision_function(X_test)        # if available use decision_function\n",
    "# else:\n",
    "#     tTest = clf.predict_proba(X_test)[:,1]       # for e.g. MLP need to use predict_proba\n",
    "tBkg = tTest[y_test==0]\n",
    "tSig = tTest[y_test==1]\n",
    "nBins = 20\n",
    "tMin = np.floor(np.min(tTest))\n",
    "tMax = np.ceil(np.max(tTest))\n",
    "bins = np.linspace(tMin, tMax, nBins+1)\n",
    "plt.xlabel('decision function $t$', labelpad=3)\n",
    "plt.ylabel('$f(t)$', labelpad=3)\n",
    "n, bins, patches = plt.hist(tSig, bins=bins, density=True, histtype='step',color = 'b', fill=True)\n",
    "n, bins, patches = plt.hist(tBkg, bins=bins, density=True, histtype='step', fill=True, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
