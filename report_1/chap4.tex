\chapter{\label{summary}Summary and Conclusions}\
In this report, we saw how we can use machine learning (Deep Neural Network) techniques to classify data from CMS, as the signal and background. We mainly focused on four simulated datasets, that was Tprime, $\Bar{t}th$, thq, and tt$\gamma \gamma$. In all of this dataset, only ttgg has non Higgs background. Here, the resonant particle, Tprime was the signal and rest, $\Bar{t}th$, thq, and tt$\gamma \gamma$ as the background. We also learn about deep learning techniques and its implementation. We also saw how deep neural networks (DNN) used to train and modify themselves to give a better optimized outputs. Usually, the output from this methods are better as compared to the other machine learning techniques used to separation, which is evident after the comparison of the output of two different model in \autoref{fig:my_label_BDT} for BDT and \autoref{fig:my_label_DNN_output} for the DNN output. The both training was done with the same dataset.\\

During the training through DNN, the output from the training of Tprime and ttgg was very good as expected with model accuracy of 93.30 \% for training and 92.06 \% for testing. ROC curve ouput is also excellent. This may be due to presence of non Higgs background, ttgg dataset as the background. When all the datasets were combined to the same DataFrame, the problem of model collapse was very feasible as also we can see from the output in \autoref{tab:my_label_0021}. The training and testing accuracy started to decrease. This model problem has been rectified with the use of multi classification training of the dataset instead of the binary classification. In multi classification each dataset will perform simultaneous training with the signal dataset simultaneously. As expected the model output are much improved compared to the previous binary classification model. The training and testing accuracy are 99.87\% and 99.86\% respectively. \\
The training over the model of multi classification can be done over any number of background. The expected resulted from this models are far better in comparison to Boosted Decision Tree(BDT), TMVA(DNN), etc\dots. As expected, we obtained a better classification output for multiclass compared to previous binary classification. Multiclass are a generalized way and less time consuming, whereas the binary classification are tedious and have to be done attentively.\\
The results of this report constitute an important development on how we can implement machine learning techniques for the search of few properties of new particles at the LHC. This result from the machine learning separation can be used to segregate the raw data from the CMS as signal and background and could be very efficient also.
% \newpage
% Address this questions:
% Why DNN, why not other?
% The Main Goal: To build a DNN to differentiate between signal and background events in an
% CMS data set
% %%%%%
% \begin{itemize}
%     \item How the signal efficiency and background efficiency are calculating?
    
% \end{itemize}

\setcounter{equation}{0}
\setcounter{table}{0}
\setcounter{figure}{0}
%\baselineskip 24pt


    



